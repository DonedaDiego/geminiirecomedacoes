from flask import Blueprint, jsonify, request

from long_short_service import LongShortService
import pandas as pd
import json
import numpy as np
from datetime import datetime, timedelta

# Criar Blueprint
long_short_bp = Blueprint('long_short', __name__)

# Inst√¢ncia do servi√ßo
service = LongShortService()

@long_short_bp.route('/api/long-short/analyze', methods=['POST'])
def analisar_long_short():
    """Executar an√°lise completa de Long & Short"""
    try:
        data = request.get_json() or {}
        
        # Par√¢metros da an√°lise
        dias = data.get('dias', 240)
        zscore_minimo = data.get('zscore_minimo', 2.0)
        investimento = data.get('investimento', 10000)
        
        # Valida√ß√µes
        if not isinstance(dias, int) or dias < 60 or dias > 500:
            return jsonify({
                'success': False,
                'error': 'Dias deve ser um n√∫mero entre 60 e 500'
            }), 400
        
        if not isinstance(zscore_minimo, (int, float)) or zscore_minimo < 1.0 or zscore_minimo > 4.0:
            return jsonify({
                'success': False,
                'error': 'Z-Score m√≠nimo deve ser um n√∫mero entre 1.0 e 4.0'
            }), 400
        
        if not isinstance(investimento, (int, float)) or investimento < 1000:
            return jsonify({
                'success': False,
                'error': 'Investimento deve ser maior que R$ 1.000'
            }), 400
        
        # Executar an√°lise
        resultado = service.executar_analise_completa(
            dias=dias,
            zscore_minimo=zscore_minimo,
            investimento=investimento
        )
        
        # ‚úÖ CORRIGIR SERIALIZA√á√ÉO DO CACHE
        if resultado['success'] and 'dados_cache' in resultado['data']:
            try:
                # Remover dados_cache da resposta principal para evitar problemas
                dados_para_cache = resultado['data'].pop('dados_cache', None)
                
                # Criar um cache simplificado e mais robusto
                if dados_para_cache:
                    dados_df = pd.read_json(dados_para_cache, orient='split')
                    
                    # Serializar de forma mais robusta
                    cache_otimizado = {
                        'index': dados_df.index.strftime('%Y-%m-%d').tolist(),
                        'columns': dados_df.columns.tolist(),
                        'data': dados_df.values.tolist()
                    }
                    
                    resultado['data']['dados_cache'] = json.dumps(cache_otimizado)
                    
            except Exception as cache_error:
                print(f"‚ö†Ô∏è Erro no cache: {cache_error}")
                # Continuar sem cache se houver erro
                resultado['data']['dados_cache'] = None
        
        return jsonify(resultado)
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@long_short_bp.route('/api/long-short/pair-detail', methods=['POST'])
def analisar_par_detalhado():
    """An√°lise detalhada de um par espec√≠fico"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Dados n√£o fornecidos'
            }), 400
        
        acao1 = data.get('acao1', '').upper()
        acao2 = data.get('acao2', '').upper()
        dados_cache = data.get('dados_cache')
        investimento = data.get('investimento', 10000)
        
        print(f"üîç Analisando par: {acao1} x {acao2}")
        print(f"üí∞ Investimento: R$ {investimento}")
        print(f"üì¶ Cache recebido: {'Sim' if dados_cache else 'N√£o'}")
        
        if not acao1 or not acao2:
            return jsonify({
                'success': False,
                'error': 'A√ß√£o1 e A√ß√£o2 s√£o obrigat√≥rios'
            }), 400
        
        # ‚úÖ MELHORAR TRATAMENTO DO CACHE
        dados = None
        
        if dados_cache:
            try:
                print("üîÑ Tentando reconstruir dados do cache...")
                
                # Tentar deserializar o cache otimizado
                if isinstance(dados_cache, str):
                    cache_data = json.loads(dados_cache)
                else:
                    cache_data = dados_cache
                
                # Verificar se √© o formato otimizado
                if isinstance(cache_data, dict) and 'index' in cache_data:
                    # Formato otimizado
                    dados = pd.DataFrame(
                        data=cache_data['data'],
                        index=pd.to_datetime(cache_data['index']),
                        columns=cache_data['columns']
                    )
                    print("‚úÖ Cache otimizado reconstitu√≠do com sucesso")
                    
                else:
                    # Formato original (fallback)
                    dados = pd.read_json(cache_data, orient='split')
                    print("‚úÖ Cache original reconstitu√≠do com sucesso")
                
                # ‚úÖ RECONSTRUIR MULTIINDEX CORRETAMENTE
                if dados is not None and len(dados.columns) > 0:
                    # Verificar se precisa reconstruir MultiIndex
                    if not isinstance(dados.columns, pd.MultiIndex):
                        print("üîß Reconstruindo MultiIndex...")
                        
                        # Criar tuplas para MultiIndex
                        tuples = []
                        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                            for ticker in service.top_50_acoes:
                                col_name = f"('{col}', '{ticker}')"
                                if col_name in dados.columns or f"{col}_{ticker}" in dados.columns:
                                    tuples.append((col, ticker))
                        
                        if tuples:
                            try:
                                columns = pd.MultiIndex.from_tuples(tuples)
                                
                                # Reordenar colunas para corresponder ao MultiIndex
                                dados_reordenados = pd.DataFrame(index=dados.index)
                                
                                for col, ticker in tuples:
                                    col_variations = [
                                        f"('{col}', '{ticker}')",
                                        f"{col}_{ticker}",
                                        f"('{col}', '{ticker}.SA')",
                                        ticker if col == 'Close' else None
                                    ]
                                    
                                    for variation in col_variations:
                                        if variation and variation in dados.columns:
                                            dados_reordenados[(col, ticker)] = dados[variation]
                                            break
                                
                                dados_reordenados.columns = pd.MultiIndex.from_tuples(
                                    [(col, ticker) for col, ticker in tuples if (col, ticker) in dados_reordenados.columns]
                                )
                                dados = dados_reordenados
                                print("‚úÖ MultiIndex reconstru√≠do com sucesso")
                                
                            except Exception as multi_error:
                                print(f"‚ö†Ô∏è Erro ao reconstruir MultiIndex: {multi_error}")
                
            except Exception as cache_error:
                print(f"‚ùå Erro ao processar cache: {cache_error}")
                dados = None
        
        # ‚úÖ FALLBACK: OBTER DADOS NOVAMENTE SE CACHE FALHAR
        if dados is None:
            print("üîÑ Cache inv√°lido, obtendo dados novamente...")
            try:
                data_fim = datetime.now()
                data_inicio = data_fim - timedelta(days=240)
                dados = service.obter_dados([acao1, acao2], data_inicio, data_fim)
                print("‚úÖ Dados obtidos diretamente")
            except Exception as fetch_error:
                print(f"‚ùå Erro ao obter dados: {fetch_error}")
                return jsonify({
                    'success': False,
                    'error': f'Erro ao obter dados das a√ß√µes: {str(fetch_error)}'
                }), 500
        
        # Verificar se as a√ß√µes existem nos dados
        if dados is None or dados.empty:
            return jsonify({
                'success': False,
                'error': 'N√£o foi poss√≠vel obter dados das a√ß√µes'
            }), 500
        
        # Verificar colunas dispon√≠veis
        print(f"üìä Colunas dispon√≠veis: {dados.columns.tolist()[:10]}...")
        
        # Verificar se as a√ß√µes est√£o nos dados
        acoes_disponiveis = []
        if isinstance(dados.columns, pd.MultiIndex):
            acoes_disponiveis = dados['Close'].columns.tolist() if 'Close' in dados.columns.levels[0] else []
        else:
            acoes_disponiveis = [col for col in dados.columns if any(ticker in col for ticker in [acao1, acao2])]
        
        print(f"üìà A√ß√µes dispon√≠veis: {acoes_disponiveis}")
        
        if isinstance(dados.columns, pd.MultiIndex):
            if 'Close' not in dados.columns.levels[0]:
                return jsonify({
                    'success': False,
                    'error': 'Dados de pre√ßos de fechamento n√£o encontrados'
                }), 400
                
            if acao1 not in dados['Close'].columns or acao2 not in dados['Close'].columns:
                return jsonify({
                    'success': False,
                    'error': f'A√ß√µes {acao1} ou {acao2} n√£o encontradas nos dados dispon√≠veis: {dados["Close"].columns.tolist()}'
                }), 400
        else:
            # Tentar encontrar as colunas das a√ß√µes
            acao1_found = any(acao1 in str(col) for col in dados.columns)
            acao2_found = any(acao2 in str(col) for col in dados.columns)
            
            if not acao1_found or not acao2_found:
                return jsonify({
                    'success': False,
                    'error': f'A√ß√µes {acao1} ou {acao2} n√£o encontradas nos dados'
                }), 400
        
        # Executar an√°lise detalhada
        print("üéØ Executando an√°lise detalhada...")
        resultado = service.analisar_par_detalhado(dados, acao1, acao2, investimento)
        
        if resultado['success']:
            print("‚úÖ An√°lise detalhada conclu√≠da com sucesso")
        else:
            print(f"‚ùå Erro na an√°lise detalhada: {resultado.get('error')}")
        
        return jsonify(resultado)
        
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico na an√°lise detalhada: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@long_short_bp.route('/api/long-short/margin-costs', methods=['POST'])
def calcular_margem_custos():
    """Calcular margem e custos operacionais"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Dados n√£o fornecidos'
            }), 400
        
        # Par√¢metros obrigat√≥rios
        valor_vendido = data.get('valor_vendido', 0)
        valor_comprado = data.get('valor_comprado', 0)
        
        # Par√¢metros opcionais
        percentual_garantia = data.get('percentual_garantia', 25.0)
        taxa_btc_anual = data.get('taxa_btc_anual', 2.0)
        dias_operacao = data.get('dias_operacao', 10)
        taxa_corretora_btc = data.get('taxa_corretora_btc', 35.0)
        
        if valor_vendido <= 0 or valor_comprado <= 0:
            return jsonify({
                'success': False,
                'error': 'Valores vendido e comprado devem ser maiores que zero'
            }), 400
        
        # C√°lculos
        garantia_venda = valor_vendido * (1 + percentual_garantia / 100)
        garantia_compra = valor_comprado * (1 + percentual_garantia / 100)
        margem_necessaria = abs(garantia_venda - garantia_compra)
        
        volume_total = valor_vendido + valor_comprado
        emolumentos = (volume_total / 10000) * 3.25
        
        taxa_btc_diaria = (taxa_btc_anual / 100) / 252
        custo_btc_periodo = valor_vendido * taxa_btc_diaria * dias_operacao
        taxa_corretora = custo_btc_periodo * (taxa_corretora_btc / 100)
        
        custo_total = margem_necessaria + emolumentos + custo_btc_periodo + taxa_corretora
        
        return jsonify({
            'success': True,
            'data': {
                'garantia_venda': garantia_venda,
                'garantia_compra': garantia_compra,
                'margem_necessaria': margem_necessaria,
                'emolumentos': emolumentos,
                'custo_btc_periodo': custo_btc_periodo,
                'taxa_corretora': taxa_corretora,
                'custo_total': custo_total,
                'parametros': {
                    'percentual_garantia': percentual_garantia,
                    'taxa_btc_anual': taxa_btc_anual,
                    'dias_operacao': dias_operacao,
                    'taxa_corretora_btc': taxa_corretora_btc
                }
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro no c√°lculo de margem: {str(e)}'
        }), 500

@long_short_bp.route('/api/long-short/stability-analysis', methods=['POST'])
def analisar_estabilidade():
    """An√°lise de estabilidade de cointegra√ß√£o por per√≠odos"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Dados n√£o fornecidos'
            }), 400
        
        acao1 = data.get('acao1', '').upper()
        acao2 = data.get('acao2', '').upper()
        dados_cache = data.get('dados_cache')
        
        print(f"üîç An√°lise de estabilidade: {acao1} x {acao2}")
        print(f"üì¶ Cache recebido: {'Sim' if dados_cache else 'N√£o'}")
        
        if not acao1 or not acao2:
            return jsonify({
                'success': False,
                'error': 'A√ß√£o1 e A√ß√£o2 s√£o obrigat√≥rios'
            }), 400
        
        # ‚úÖ USAR A MESMA L√ìGICA DE RECONSTRU√á√ÉO DO CACHE DA FUN√á√ÉO ANTERIOR
        dados = None
        
        if dados_cache:
            try:
                print("üîÑ Reconstruindo dados do cache para an√°lise de estabilidade...")
                
                # Tentar deserializar o cache otimizado
                if isinstance(dados_cache, str):
                    cache_data = json.loads(dados_cache)
                else:
                    cache_data = dados_cache
                
                # Verificar se √© o formato otimizado
                if isinstance(cache_data, dict) and 'index' in cache_data:
                    # Formato otimizado
                    dados = pd.DataFrame(
                        data=cache_data['data'],
                        index=pd.to_datetime(cache_data['index']),
                        columns=cache_data['columns']
                    )
                    print("‚úÖ Cache otimizado reconstitu√≠do")
                    
                else:
                    # Formato original (fallback)
                    dados = pd.read_json(cache_data, orient='split')
                    print("‚úÖ Cache original reconstitu√≠do")
                
                # ‚úÖ RECONSTRUIR MULTIINDEX CORRETAMENTE (MESMA L√ìGICA)
                if dados is not None and len(dados.columns) > 0:
                    # Verificar se precisa reconstruir MultiIndex
                    if not isinstance(dados.columns, pd.MultiIndex):
                        print("üîß Reconstruindo MultiIndex para estabilidade...")
                        
                        # Criar tuplas para MultiIndex
                        tuples = []
                        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                            for ticker in service.top_50_acoes:
                                col_name = f"('{col}', '{ticker}')"
                                if col_name in dados.columns or f"{col}_{ticker}" in dados.columns:
                                    tuples.append((col, ticker))
                        
                        if tuples:
                            try:
                                columns = pd.MultiIndex.from_tuples(tuples)
                                
                                # Reordenar colunas para corresponder ao MultiIndex
                                dados_reordenados = pd.DataFrame(index=dados.index)
                                
                                for col, ticker in tuples:
                                    col_variations = [
                                        f"('{col}', '{ticker}')",
                                        f"{col}_{ticker}",
                                        f"('{col}', '{ticker}.SA')",
                                        ticker if col == 'Close' else None
                                    ]
                                    
                                    for variation in col_variations:
                                        if variation and variation in dados.columns:
                                            dados_reordenados[(col, ticker)] = dados[variation]
                                            break
                                
                                dados_reordenados.columns = pd.MultiIndex.from_tuples(
                                    [(col, ticker) for col, ticker in tuples if (col, ticker) in dados_reordenados.columns]
                                )
                                dados = dados_reordenados
                                print("‚úÖ MultiIndex reconstru√≠do para estabilidade")
                                
                            except Exception as multi_error:
                                print(f"‚ö†Ô∏è Erro ao reconstruir MultiIndex: {multi_error}")
                
            except Exception as cache_error:
                print(f"‚ùå Erro ao processar cache: {cache_error}")
                dados = None
        
        # ‚úÖ FALLBACK: OBTER DADOS NOVAMENTE SE CACHE FALHAR
        if dados is None:
            print("üîÑ Cache inv√°lido, obtendo dados novamente para estabilidade...")
            try:
                data_fim = datetime.now()
                data_inicio = data_fim - timedelta(days=240)
                dados = service.obter_dados([acao1, acao2], data_inicio, data_fim)
                print("‚úÖ Dados obtidos diretamente para estabilidade")
            except Exception as fetch_error:
                print(f"‚ùå Erro ao obter dados: {fetch_error}")
                return jsonify({
                    'success': False,
                    'error': f'Erro ao obter dados das a√ß√µes: {str(fetch_error)}'
                }), 500
        
        # Verificar se as a√ß√µes existem nos dados
        if dados is None or dados.empty:
            return jsonify({
                'success': False,
                'error': 'N√£o foi poss√≠vel obter dados das a√ß√µes'
            }), 500
        
        # ‚úÖ VERIFICAR ESTRUTURA DOS DADOS
        print(f"üìä Estrutura dos dados: {type(dados.columns)}")
        print(f"üìà Shape dos dados: {dados.shape}")
        
        # Verificar se as a√ß√µes est√£o dispon√≠veis
        if isinstance(dados.columns, pd.MultiIndex):
            if 'Close' not in dados.columns.levels[0]:
                return jsonify({
                    'success': False,
                    'error': 'Dados de pre√ßos de fechamento n√£o encontrados'
                }), 400
                
            acoes_disponiveis = dados['Close'].columns.tolist()
            if acao1 not in acoes_disponiveis or acao2 not in acoes_disponiveis:
                return jsonify({
                    'success': False,
                    'error': f'A√ß√µes {acao1} ou {acao2} n√£o encontradas. Dispon√≠veis: {acoes_disponiveis}'
                }), 400
        else:
            return jsonify({
                'success': False,
                'error': f'Estrutura de dados inv√°lida. Esperado MultiIndex, recebido: {type(dados.columns)}'
            }), 400
        
        # ‚úÖ AN√ÅLISE DE ESTABILIDADE POR PER√çODOS COM MELHOR TRATAMENTO DE ERROS
        periodos = [60, 90, 120, 140, 180, 200, 240]
        resultados = []
        
        print("üìä Iniciando an√°lise de estabilidade por per√≠odos...")
        
        for periodo in periodos:
            try:
                print(f"üîç Analisando per√≠odo de {periodo} dias...")
                
                # Verificar se temos dados suficientes
                if len(dados) < periodo:
                    print(f"‚ö†Ô∏è Dados insuficientes para per√≠odo de {periodo} dias")
                    resultados.append({
                        'periodo': periodo,
                        'pvalor_cointegra√ß√£o': None,
                        'meia_vida': None,
                        'r_squared': None,
                        'status': 'Dados Insuficientes'
                    })
                    continue
                
                dados_recentes = dados.tail(periodo)
                
                # Verificar se as a√ß√µes t√™m dados v√°lidos no per√≠odo
                serie1 = dados_recentes['Close'][acao1].dropna()
                serie2 = dados_recentes['Close'][acao2].dropna()
                
                if len(serie1) < 30 or len(serie2) < 30:
                    print(f"‚ö†Ô∏è Dados insuficientes para {acao1} ou {acao2} no per√≠odo de {periodo} dias")
                    resultados.append({
                        'periodo': periodo,
                        'pvalor_cointegra√ß√£o': None,
                        'meia_vida': None,
                        'r_squared': None,
                        'status': 'Dados Insuficientes'
                    })
                    continue
                
                # Teste de cointegra√ß√£o
                from statsmodels.tsa.stattools import coint
                from statsmodels.regression.linear_model import OLS
                
                try:
                    _, pvalor, _ = coint(serie1, serie2)
                    print(f"‚úÖ Cointegra√ß√£o calculada para {periodo} dias: p-valor = {pvalor:.4f}")
                except Exception as coint_error:
                    print(f"‚ùå Erro no teste de cointegra√ß√£o para {periodo} dias: {coint_error}")
                    resultados.append({
                        'periodo': periodo,
                        'pvalor_cointegra√ß√£o': None,
                        'meia_vida': None,
                        'r_squared': None,
                        'status': 'Erro Cointegra√ß√£o'
                    })
                    continue
                
                # Calcular spread e meia-vida
                try:
                    modelo = OLS(serie1, serie2).fit()
                    spread = serie1 - modelo.params[0] * serie2
                    meia_vida = service.calcular_meia_vida(spread) if len(spread.dropna()) > 1 else None
                    print(f"‚úÖ Meia-vida calculada para {periodo} dias: {meia_vida}")
                except Exception as spread_error:
                    print(f"‚ùå Erro no c√°lculo do spread para {periodo} dias: {spread_error}")
                    meia_vida = None
                    modelo = None
                
                # Preparar resultado
                status = 'Cointegrado' if pvalor < 0.05 else 'N√£o Cointegrado'
                
                resultado_periodo = {
                    'periodo': periodo,
                    'pvalor_cointegra√ß√£o': round(pvalor, 4) if pvalor is not None else None,
                    'meia_vida': round(meia_vida, 2) if meia_vida is not None else None,
                    'r_squared': round(modelo.rsquared, 4) if modelo is not None else None,
                    'status': status
                }
                
                resultados.append(resultado_periodo)
                print(f"‚úÖ Per√≠odo {periodo} conclu√≠do: {status}")
                
            except Exception as e:
                print(f"‚ùå Erro geral no per√≠odo {periodo}: {str(e)}")
                resultados.append({
                    'periodo': periodo,
                    'pvalor_cointegra√ß√£o': None,
                    'meia_vida': None,
                    'r_squared': None,
                    'status': 'Erro'
                })
        
        # ‚úÖ DIAGN√ìSTICO GERAL MELHORADO
        periodos_validos = [r for r in resultados if r['status'] not in ['Erro', 'Dados Insuficientes', 'Erro Cointegra√ß√£o']]
        periodos_cointegrados = sum(1 for r in periodos_validos if r['status'] == 'Cointegrado')
        total_periodos = len(periodos_validos)
        
        if total_periodos == 0:
            diagnostico = "N√£o foi poss√≠vel analisar nenhum per√≠odo"
            status_icon = "‚ùå"
            r2_medio = 0
        else:
            r2_values = [r['r_squared'] for r in resultados if r['r_squared'] is not None]
            r2_medio = sum(r2_values) / len(r2_values) if r2_values else 0
            
            if periodos_cointegrados == total_periodos:
                diagnostico = "Cointegra√ß√£o est√°vel em todos os per√≠odos"
                status_icon = "‚úÖ"
            elif periodos_cointegrados >= total_periodos * 0.7:
                diagnostico = "Cointegra√ß√£o presente na maioria dos per√≠odos"
                status_icon = "‚ö†Ô∏è"
            else:
                diagnostico = "Cointegra√ß√£o inst√°vel ou ausente"
                status_icon = "‚ùå"
        
        print(f"üéØ Diagn√≥stico final: {diagnostico}")
        print(f"üìä Per√≠odos cointegrados: {periodos_cointegrados}/{total_periodos}")
        
        return jsonify({
            'success': True,
            'data': {
                'analise_periodos': resultados,
                'diagnostico': {
                    'status_icon': status_icon,
                    'texto': diagnostico,
                    'periodos_cointegrados': periodos_cointegrados,
                    'total_periodos': total_periodos,
                    'r2_medio': round(r2_medio, 4)
                }
            }
        })
        
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico na an√°lise de estabilidade: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'Erro na an√°lise de estabilidade: {str(e)}'
        }), 500

@long_short_bp.route('/api/long-short/setores', methods=['GET'])
def obter_setores():
    """Obter mapeamento de setores das a√ß√µes"""
    try:
        return jsonify({
            'success': True,
            'data': {
                'setores': service.setores,
                'acoes_disponiveis': service.top_50_acoes
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro ao obter setores: {str(e)}'
        }), 500

@long_short_bp.route('/api/long-short/status', methods=['GET'])
def status_servico():
    """Status do servi√ßo Long & Short"""
    return jsonify({
        'success': True,
        'data': {
            'status': 'online',
            'total_acoes': len(service.top_50_acoes),
            'setores_unicos': len(set(service.setores.values())),
            'version': '1.0.0'
        }
    })